{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import io, audio, keras\n",
    "import pandas\n",
    "import numpy\n",
    "import os\n",
    "import gzip\n",
    "import zlib\n",
    "from Brett import db, data_util\n",
    "from functools import reduce, partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = lambda *F: reduce(lambda f, g: lambda x: f(g(x)), F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '/scr-ssd/mimic/'\n",
    "def get_rec_path(recID, part):\n",
    "    return ROOT + part + '/' + str(recID[0]) + '_' + str(recID[1]).zfill(4)\n",
    "\n",
    "def read_rec(recID, part='train'):\n",
    "    return db.read_record(get_rec_path(recID, part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_path = lambda rec, ext: '/scr-ssd/tmp/' + rec.record_name + '.' + ext\n",
    "\n",
    "def encode_recs(encode, recs, ext):\n",
    "    for rec in recs:\n",
    "        io.write_file(encoding_path(rec, ext), encode(rec.d_signal))\n",
    "\n",
    "def decode_recs(decode, recs, ext):\n",
    "    decode = compose(\n",
    "        lambda x: x.numpy(), \n",
    "        decode, \n",
    "        io.read_file, \n",
    "        lambda rec: encoding_path(rec, ext)\n",
    "    )\n",
    "    return [decode(rec) for rec in recs]\n",
    "\n",
    "def get_size_factor(recs, ext):\n",
    "    factors = []\n",
    "    for rec in recs:\n",
    "        s1 = os.path.getsize(ROOT + 'train/' + rec.record_name + '_x.flac')\n",
    "        s2 = os.path.getsize(encoding_path(rec, ext))\n",
    "        factors.append(s2/s1)\n",
    "    return numpy.round(numpy.mean(factors), 2)\n",
    "\n",
    "def distance_decoded(decode, recs, ext):\n",
    "    X = [rec.d_signal for rec in recs]\n",
    "    X_ = decode_recs(decode, recs, ext)\n",
    "    return sum(numpy.abs(x != x_).sum() for x, x_ in zip(X, X_))\n",
    "\n",
    "def test_codec(recs, encode, decode, ext):\n",
    "    print('Encoding Time')\n",
    "    %time encode_recs(encode, recs, ext)\n",
    "    print('\\n' 'Size Factor:', get_size_factor(recs, ext))\n",
    "    print('\\n' 'Decoding Time')\n",
    "    %time decode_recs(decode, recs, ext)\n",
    "    print('\\n' 'D(decoded, original):', distance_decoded(decode, recs, ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = {\n",
    "    'input_sigs': ['II', 'V', 'PLETH', 'RESP'],\n",
    "    'max_sig_len': 125 * 60 * 60 * 24,\n",
    "    'resp_scale': 5,\n",
    "    'layer_count_a': 3,\n",
    "    'layer_count_b': 5,\n",
    "    'window_size': 512,\n",
    "    'activation': 'relu',\n",
    "    'dropout': 0.2,\n",
    "    'filter_count': 128,\n",
    "    'dense_units': 64,\n",
    "    'kernel_size_a': 16,\n",
    "    'stride_a': 4,\n",
    "    'kernel_size_b': 4,\n",
    "    'batch_size': 8,\n",
    "    'batch_buffer_size': 2,\n",
    "    'windows_per_record': 10,\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 3e-4,\n",
    "    'pressure_smoothing_window': 300\n",
    "}\n",
    "\n",
    "metadata, pressures = data_util.load_metadata_and_pressures(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(3189000,   10),\n",
       "            (3987729,   11),\n",
       "            (3334855,  805),\n",
       "            (3357886,  729),\n",
       "            (3472281, 1342)],\n",
       "           names=['record_id', 'segment'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 7.24 s, total: 36.7 s\n",
      "Wall time: 36.7 s\n"
     ]
    }
   ],
   "source": [
    "recIDs = metadata.sample(frac=1, random_state=7).index[:200]\n",
    "display(recIDs[:5])\n",
    "%time recs = [read_rec(i) for i in recIDs]\n",
    "for rec in recs:\n",
    "    rec.d_signal = db.to_digital(rec.p_signal, rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Time\n",
      "CPU times: user 2.78 s, sys: 5.66 s, total: 8.44 s\n",
      "Wall time: 8.47 s\n",
      "\n",
      "Size Factor: 3.46\n",
      "\n",
      "Decoding Time\n",
      "CPU times: user 2.47 s, sys: 3.66 s, total: 6.13 s\n",
      "Wall time: 6.13 s\n",
      "\n",
      "D(decoded, original): 0\n"
     ]
    }
   ],
   "source": [
    "encode_serial = lambda x: io.serialize_tensor(x).numpy()\n",
    "decode_serial = lambda z: io.parse_tensor(z, out_type='int16')\n",
    "test_codec(recs, encode_serial, decode_serial, ext='serial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Time\n",
      "CPU times: user 12.8 s, sys: 7.81 s, total: 20.6 s\n",
      "Wall time: 20.6 s\n",
      "\n",
      "Size Factor: 3.46\n",
      "\n",
      "Decoding Time\n"
     ]
    }
   ],
   "source": [
    "encode_wav = lambda x: audio.encode_wav(x / 2**15, 125)\n",
    "decode_wav = lambda z: keras.backend.round(audio.decode_wav(z).audio * 2**15)\n",
    "test_codec(recs, encode_wav, decode_wav, ext='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_serial = lambda x: io.serialize_tensor(x).numpy()\n",
    "decode_serial = lambda z: io.parse_tensor(z, out_type='int16')\n",
    "unzip = lambda t: lambda z: io.decode_compressed(z, compression_type=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GZIP Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Time\n",
      "CPU times: user 2min 31s, sys: 5.6 s, total: 2min 36s\n",
      "Wall time: 2min 36s\n",
      "\n",
      "Size Factor: 2.23\n",
      "\n",
      "Decoding Time\n",
      "CPU times: user 21.6 s, sys: 4.7 s, total: 26.3 s\n",
      "Wall time: 26.3 s\n",
      "\n",
      "D(decoded, original): 0\n"
     ]
    }
   ],
   "source": [
    "compress_gzip = lambda x: gzip.compress(x, compresslevel=6)\n",
    "encode_gzip = compose(compress_gzip, encode_serial)\n",
    "decode_gzip = compose(decode_serial, unzip('GZIP'))\n",
    "test_codec(recs, encode_gzip, decode_gzip, ext='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLIB Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Time\n",
      "CPU times: user 2min 29s, sys: 4.8 s, total: 2min 33s\n",
      "Wall time: 2min 33s\n",
      "\n",
      "Size Factor: 2.23\n",
      "\n",
      "Decoding Time\n",
      "CPU times: user 20.3 s, sys: 4.57 s, total: 24.8 s\n",
      "Wall time: 24.8 s\n",
      "\n",
      "D(decoded, original): 0\n"
     ]
    }
   ],
   "source": [
    "compress_zlib = lambda x: zlib.compress(x, level=6)\n",
    "encode_zlib = compose(compress_zlib, encode_serial)\n",
    "decode_zlib = compose(decode_serial, unzip('ZLIB'))\n",
    "test_codec(recs, encode_zlib, decode_zlib, ext='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
